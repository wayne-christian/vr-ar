<!doctype html>
<html>
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
<title>VIRTUAL AND AUGMENTED REALITY (CMP-VAR02021):Augmented Reality</title>
<link rel="stylesheet" href="css/reveal.css">
<link rel="stylesheet" href="css/theme/night.css">

<!-- Theme used for syntax highlighting of code -->
<link rel="stylesheet" href="lib/css/zenburn.css">
<link rel="stylesheet" href="css/custom.css">

<!-- Printing and PDF exports --> 
<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>
</head>
<body>
<div class="reveal">
  <div class="slides">
    <section data-background-transition="convex" data-background="#333333">
      <h2 >Hello</h2>
      <p style="color:#F8AA00">VIRTUAL AND AUGMENTED REALITY (CMP-VAR-2122)</p>
        <p>Session Code: 091028</p>
    </section>
    <section data-background-transition="convex" data-background-video="https://wayne-christian.github.io/WEB-AUTH-PRESENTATIONS/assets/week1assets/rainingcode.mp4" data-background-video-loop="loop">
      <h3 >Wayne Christian</h3>
      <p style="color:#F8AA00">Designer, Developer, Director & Senior Lecturer</p>
    </section>
    <section data-menu-title="wayne"  data-background="assets/brain.jpg" data-background-size="cover" data-background-color="#fff">
      <h4 class="fragment fade-up"><span class="dark-back">Teach in the School of Design and School of Computer Science</span></h4>
    </section>

    <section data-menu-title="waynes loop1" data-background-transition="convex" data-background-video="assets/blast.mp4" data-background-video-loop="loop">
      <h4 class="fragment fade-up"><span class="dark-back">Programme Lead for IxD</span></h4>
    </section>
    <section data-menu-title="waynes loop" data-background-transition="convex" data-background-video="assets/ade_loop.mp4" data-background-video-loop="loop"> </section>
      
      <section data-menu-title="wayne" class="fragment" data-background="assets/frontiers/storm3.jpg" data-background-size="cover" data-background-color="#fff"><h4 class="fragment fade-up"><span class="dark-back">I am an interactive designer</span></h4></section>
      
      <section data-menu-title="wayne" class="fragment" data-background="assets/frontiers/storm2.jpg" data-background-size="cover" data-background-color="#fff"><h4 class="fragment fade-up"><span class="dark-back">Interested in how and why,</span></h4></section>
       <section data-menu-title="wayne" class="fragment" data-background="assets/frontiers/storm1.jpg" data-background-size="cover" data-background-color="#fff"><h4 class="fragment fade-up"><span class="dark-back">people interact with experiences.</span></h4></section>
      
    <section data-menu-title="wayne" class="fragment" data-background="https://wayne-christian.github.io/WEB-AUTH-PRESENTATIONS/assets/week0assets/holo1.jpg" data-background-size="cover" data-background-color="#fff">
      <p class=""><span class="dark-back">My current research focuses on Mixed Reality and Augmented Reality(focused on UX)</span></p>
    </section>
    <section data-menu-title="Hololens example" data-background-transition="convex" data-background-video="https://wayne-christian.github.io/WEB-AUTH-PRESENTATIONS/assets/week0assets/holo1.mp4" > </section>
      
               <section data-menu-title="Start" data-background="assets/intro1.jpg"> </section>
    <section data-background="assets/intro1.jpg">
              <audio data-autoplay src="assets/Introduction.mp3"></audio>
            </section>

    <section data-state="compositions 1" data-background="assets/Composite.jpg" data-background-size="contain" data-background-color="#fff"> </section>
    
    <!--  wireframe // manage-->
    <section data-state="wireframe" data-background="assets/wireframe.jpg" data-background-size="contain" data-background-color="#fff"> </section>
    
    <!--  design-->
    <section data-state="design" data-background="assets/design1.png" data-background-size="cover" data-background-color="#5D5D5D"> </section>
    <!--  oclusion-->
    <section data-background-video="assets/end.mp4" > </section>
    
    <!--  polys-->
    <section  data-background-video-loop="loop" data-background-video="assets/3d1.mp4"> </section>
    <section data-menu-title="RAF100" data-background-transition="convex" data-background-video="assets/raf100.mp4" > </section>
    <!--<section data-state="design" data-background="assets/walk.png" data-background-size="contain" data-background-color="#fff"> </section>-->
      
      <!--////////////////////////////////////////////////////////////////////////////////////////////////////
      ////////////////////////////////////////////////////////////////////////////////////////////////////
      //VESTIGIA-->
          <section><h4>Vestigiascope</h4>
              <p>This application turns your mobile device into a Vestigiascope.  This experimental technology has been created to enable participants to journey through city of Lincoln and uncover the ghosts of the past, as part of the Distant Christmas project. These ghosts, or what scientists call "vestigia", are the echoes of history recorded onto the fabric of the world around uss</p>
              <p class="tiny">I will be doing a case study talk on making this after xmas</p>
      
      </section>
       <section data-menu-title="" data-background="assets/frontiers/vestigia1.png" data-background-size="900px" data-background-color="#fff"> </section>
     
      <section data-menu-title="vest 2" data-background-transition="convex" data-background-video="assets/frontiers/vest2.mp4" data-background-size="contain" data-background-video-muted> </section>
      
      <section data-menu-title="vest 2" data-background-transition="convex" data-background-video="assets/frontiers/vest3.mp4" data-background-size="contain" data-background-video-muted> </section>
      
      <section data-menu-title="vest1" data-background-transition="convex" data-background-video="assets/frontiers/vest5.mp4" data-background-size="contain" > </section>
      
       <section data-menu-title="vest 2" data-background-transition="convex" data-background-video="assets/frontiers/vest4.mov" data-background-size="contain"> </section>
      
      <section data-menu-title="vest1" data-background-transition="convex" data-background-video="assets/frontiers/vest1.mp4" data-background-size="contain" > </section>
      
      

    <section data-background-transition="convex" data-background="https://wayne-christian.github.io/WEB-AUTH-PRESENTATIONS/assets/week5assets/cow-dancing.gif" data-background-size="300px" >
      <h3>VR considerations</h3>
    </section>

    <section data-background-transition="convex" data-background="">
      <p ><strong>VR Report:</strong></p>
      <p class="fragment tight bullet small" style="">Assets not consistent?</p>
      <p class="fragment tight bullet small" style="">Sound?</p>
      <p class="fragment tight bullet small" style="">Context?</p>
      <p class="fragment tight bullet small" style="">Consider the factors that make VR immersive and what may break immersion.</p>
    </section>
    <section data-background="assets/brain.jpg" data-background-size="cover" data-background-color="#ff000">
      <h2>
        <ul class="dark">
          <li class="fragment fade-up"><span class="dark-back">Ideation</span></li>
          <li class="fragment fade-up"><span class="dark-back">Research</span></li>
          <li class="fragment fade-up"><span class="dark-back">Experimentation</span></li>
          <li class="fragment fade-up"><span class="dark-back">Development</span> </li>
          <li class="fragment fade-up"><span class="dark-back">Refinement</span></li>
          <li class="fragment fade-up"><span class="dark-back" style="color: red">Evaluation</span></li>
        </ul>
      </h2>
    </section>
    <section data-state="intro" data-background="assets/ar/ar_front.jpg">
      <h3><span class="dark-back">Augmented Reality</span></h3>
    </section>
        
    <section data-background="#222222">
      <iframe src="https://embed.polleverywhere.com/multiple_choice_polls/qVaIvG4c7eaC1TcdKnOQD?controls=none&short_poll=true" width="1200" height="800" frameBorder="0"></iframe>
    </section>
      
    <section>
      <h3>AR assessment</h3>
      <p>1. Combine virtual and real information, with the real world as the primary place of action;</p>
      <p>2. Be interactive with real-time updates to content or object (GUI);</p>
      <p>3. Have virtual information registered in 3D space, in the physical environment.</p>
      <p>4. A Report.</p>
    </section>
    <section data-menu-title="today" data-background-transition="convex" style="" >
      <p>To day we will look at.<br>
      </p>
      <p class="fragment  bullet">Brief AR history</p>
      <p class="fragment  bullet">Market</p>
      <p class="fragment  bullet">AR types and examples</p>
      <p class="fragment  bullet">Cool examples</p>
      <p class="fragment bullet">SDK ecosystem</p>
      <p class="fragment bullet">Immersion</p>
    </section>
    <section>
      <p>Augmented reality (AR) is defined as “a live direct or an indirect view of a physical, real-world environment whose elements are augmented by computer-generated sensory input, such as sound, graphics or GPS data.”</p>
      <p class="tiny">Augmented Reality – Implications toward Virtual Reality, Human Perception and Performance, 2019</p>
    </section>
    <section>
      <p>More commonly..</p>
      <p>An enhanced version of reality created by the use of technology to overlay digital information on an image of something being viewed through a device (such as a smart-phone camera or HMD (There are others)</p>
    </section>
    <section data-background-video="assets/ar/ar_vid8.mp4"></section>
         <section data-menu-title="ar world" data-background-transition="convex" data-background-video="assets/ar1.mp4" > <p class="tiny"><span class="dark-back">Hyper-Reality - Keiichi Matsuda</span></p></section>
    <section>
      <h3>History</h3>
      <p>AR origins AR similar to VR</p>
      <p></p>
    </section>
    <section>
      <p><strong>The Master Key</strong> written in 1901. In the novel, Frank Baum described a device that can mark people with letters and show their character in real time.</p>
    </section>
    <section> <img src="assets/ar/firstar.jpeg"/>
      <p>The first VR-AR helmet  in history was developed by a Harvard Professor Ivan Sutherland and his student Bob Sproull in 1968. It was called <strong>“The Sword of Damocles.”</strong> (Patricks slides week 1)</p>
    </section>
    <section> <img src="assets/ar/arhistory2.jpg"/>
      <p><strong>1980:</strong> EyeTap, the first portable AR device</p>
    </section>
    <section> <img src="assets/ar/arhistory3.gif"/>
      <p><strong>1999:</strong> Hirokazu Kato from the Nara Institute of Science and Technology released a unique piece of software called the ARToolKit..</p>
    </section>
    <section>
      <h2>2008</h2>
      <p>What happened that made AR accessible</p>
      <h3 class="fragment">Smart Phones</h3>
    </section>
    <section>
      <p>The rise of hand-held AR is the tipping point for the technology being truly pervasive.</p>
    </section>
    <section>
      <h2>2021 (Now)</h2>
    </section>
    <section data-background="assets/ar/Mobile-AR-Stats.jpg" data-background-size="800px" data-background-color="#2e2f2e"></section>
    <section data-background="assets/ar/Mobile-AR-Stats2.jpg" data-background-size="700px" data-background-color="#383838"></section>
       <section data-background="assets/Mobile-AR-Stats3.jpg" data-background-size="600px" data-background-color="#353535"></section>
    <section>
      <h3>Augmented Reality vs Virtual Reality</h3>
      <p>Unlike virtual reality, which requires you to inhabit an entirely virtual environment, augmented reality uses your existing natural environment and simply overlays virtual information on top of it. </p>
      <p class="fragment">As both virtual and real worlds harmoniously coexist, users of augmented reality experience an improved natural world where virtual information is used as a tool to provide assistance in everyday activities.</p>
    </section>
    <section>
      <p>Simply</p>
      <h3>VR creates environments and AR alters environments</h3>
    </section>
    <section data-background="assets/ar/types_diagram.jpg" data-background-size="800px" data-background-color="#383838"> </section>
    <section data-background="assets/ar/types_diagram2.jpg" data-background-size="800px" data-background-color="#383838"> </section>
    <section>
      <p>AR is rapidly growing in popularity because it brings elements of the virtual world, into our real world, thus enhancing the things we see, hear, and feel. When compared to other reality technologies, augmented reality lies in the middle of the mixed reality spectrum; between the real world and the virtual world </p>
    </section>
    <section>
      <h3>"<strong>70%</strong> OF SNAPCHAT’S <strong>186 MILLION DAILY</strong> USERS ACTIVATE AR LENSES DAILY"</h3>
    </section>
    <section data-menu-title="today" data-background-transition="convex" style="" >
      <p>Types of AR<br>
        <span class="small"> There are overlaps but are some more immersive than others?</span></p>
      <p class="fragment  bullet">Marker (better now with multiple markers)</p>
      <p class="fragment  bullet">Marker less (SLAM, Geolocation)</p>
      <p class="fragment  bullet">SLAM (Occlusion)</p>
      <p class="fragment  bullet">Facial & body analysis</p>
      <p class="fragment  bullet">Social</p>
      <p class="fragment bullet">Superimposition</p>
      <p class="fragment  bullet">Projection (not on a device!)</p>
    </section>
    <section data-background="assets/od.png" data-background-size="contain" data-background-color="#fff">
      <h3 style="color: black" >Visual-inertial Odometry</h3>
      <p class="fragment"> <span class="dark-back" >To create a correspondence between real and virtual spaces, AR SDK’s uses a technique called visual-inertial odometry. This process combines information from the device’s motion sensing hardware with computer vision analysis of the scene visible to the device’s camera</span></p>
    </section>
    <section>
      <h3>Marker Based Augmented Reality</h3>
      <p class="small">(also called Image Recognition) </p>
      <p class="bullet fragment  ">Uses a camera and some type of visual marker, such as a QR/2D code-a 3d object is different</p>
      <p class="bullet fragment  ">Camera on the device distinguishes a marker from any other real world object. </p>
      <p class="bullet fragment  ">Distinct, but simple patterns (such as a QR code) are easily recognized and do not require a lot of processing power to read. </p>
      <p class="bullet fragment  ">The position and orientation is also calculated, in which some type of content and/or information is then overlaid the marker.</p>
    </section>
    <section  data-background-size ="contain" data-background-video-loop="loop" data-background-video="assets/test.mp4"> </section>
    <section data-background-video="assets/ar/machine.mp4">  <p><span class="dark-back">Marker</span></p></section>

    <section data-background-video="assets/ar/disney.mp4">
      <p><span class="dark-back">Marker</span></p>
    </section>
    <section data-background-video="assets/ar/ar_vid16.mp4"></section>
    <section data-background-video="assets/ar/ar_vid7.mp4"></section>
    <section>
      <h3>Markerless Augmented Reality</h3>
      <p class="bullet ">One of the most widely implemented applications of augmented reality</p>
      <p class="bullet fragment  ">Also called location-based, position-based, or GPS) </p>
      <p class="bullet fragment  ">uses a GPS, digital compass, velocity meter, or accelerometer which is embedded in the device to provide data based on your location. </p>
      <p class="bullet fragment  ">leverage’s the wide availability of smart-phones and location detection features they provide. </p>
      <p class="bullet fragment  ">It is most commonly used for mapping directions, finding nearby businesses, and other location-centric mobile applications.</p>
    </section>
    <section data-background-video="assets/ar/ar_vid9.mp4">
      <h3>Markerless Augmented Reality</h3>
    </section>
    <section data-background-video="assets/ar/ar_vid17.mp4"></section>
    <section data-background-video="assets/ar/ar_vid13.mp4"></section>
    <section data-background-video="http://interactivedesignlincoln.co.uk/raf100/assets/end.mp4"></section>
    <section>
      <h3>SLAM (simultaneous localization and mapping)</h3>
      <p>SLAM is a technology that recognizes surfaces and allows us to place AR content without the need to scan an image.(fairly old) </p>
    </section>
    <section data-background-video="assets/ar/ar_vid4.mp4"></section>
    <section data-background-video="assets/ar/ar_vid2.mp4"></section>
    <section>
      <h3>SLAM & Occlusion</h3>
      <p class="bullet">The release of Apple’s AR Kit 3 now provides the ability to improve the realism of SLAM based AR scenes using object occlusion.</p>
      <p class="bullet fragment">We now have the ability to make 3D content intelligently pass in front and behind real world objects and people to create truly immersive content.</p>
      <p class="small fragment ">Great For: Entertainment, Large Scale Product Visualisations</p>
    </section>
    <section data-background-video="assets/ar/occlusion.mp4"> </section>
    <section data-background-video="assets/ar/ar_vid11.mp4"> </section>
    <section>
      <h3>Facial Analysis</h3>
      <p class="bullet">TrueDepth technology present on the latest iOS devices can now..</p>
      <p class="bullet fragment  ">Analyse facial features</p>
      <p class="bullet fragment  ">Accurately capture a range of 3D information. </p>
      <p class="bullet fragment  ">Useful tool for retailers dealing in head and eye wear.</p>
      <p class="bullet fragment  ">Opportunity to visualise products in AR</p>
      <p class="bullet fragment  ">Get personalised recommendations of sizing and styles that will best suit their needs.</p>
      <p class="small fragment  ">Great For: Wearables, Product Visualisation</p>
    </section>
    <section data-background-video="assets/ar/ar_vid19.mp4"></section>
    <section>
      <h3>Social AR (Filters)</h3>
      <p class="bullet">FaceBook’s new development platform, Spark AR, we can create a range of AR filters, interactive adverts and mini experiences ready for use on FaceBook and Instagram.</p>
      <p class="bullet fragment  ">Social AR is a great tool to integrate into marketing campaigns </p>
      <p class="bullet fragment  ">strong entertainment value and ‘share-ability’. </p>
      <p class="bullet fragment  ">It can be integrated straight into existing social media timelines, ensuring the content gets a wide exposure.</p>
      <p class="small fragment  ">Great For: Entertainment, Marketing</p>
    </section>
    <section data-background-video="assets/ar/dior.mp4"></section>
    <section>
      <h3>Body Tracking</h3>
      <p class="bullet">Body tracking allows us to overlay digital content and effects over user’s hands and body movements.</p>
      <p class="bullet fragment  ">Gives the user the ability to manipulate and interact with what they see.</p>
      <p class="bullet fragment  ">Allows us to be much more creative in the ways we ask audiences to interact with AR experiences.</p>
      <p class="small fragment  ">Great For: Entertainment, Apps encouraging physical activity.</p>
    </section>
    <section data-background-video="assets/ar/ar_vid21.mp4" data-background-size ="contain"></section>
    <section data-background-video="assets/ar/ar_vid22.mp4" data-background-size ="contain"></section>
    <section data-background-video="assets/ar/ar_vid23.mp4"></section>
    <section data-background-video="assets/ar/ar_vid10.mp4"></section>
    <section data-background-video="assets/ar/ar_vid20.mp4"></section>
    <section>
      <p>Military</p>
    </section>
    <section data-background-video="assets/ar/ar_vid15.mp4"></section>
    
    <!--	  <section>
Projection Based Augmented Reality
Projection Based Augmented RealityProjection based augmented reality works by projecting artificial light onto real world surfaces. Projection based augmented reality applications allow for human interaction by sending light onto a real world surface and then sensing the human interaction (i.e. touch) of that projected light. Detecting the user’s interaction is done by differentiating between an expected (or known) projection and the altered projection (caused by the user’s interaction). Another interesting application of projection based augmented reality utilizes laser plasma technology to project a three-dimensional (3D) interactive holograminto mid-air.
</section>-->
    <section>
      <h3>Superimposition Based Augmented Reality</h3>
      <p class="bullet">Partially or fully replaces the original view of an object with a newly augmented view of that same object. </p>
      <p class="bullet">Object recognition plays a vital role because the application cannot replace the original view with an augmented one if it cannot determine what the object is.</p>
    </section>
    <section data-background-video="assets/ar/ikea.mp4"></section>
    <section data-background-video="assets/ar/3dobj.mp4"></section>
    <section>
      <h3>Other Examples</h3>
    </section>
    <section data-background-video="assets/ar/pepsi.mp4"></section>
    <section data-background-video="assets/ar/ar_vid3.mp4"></section>
    <section data-background-video="assets/ar/ar_vid4.mp4">
      <p>volumetric filming</p>
    </section>
    <section data-background-video="assets/ar/ar_vid5.mp4"></section>
    <section data-background-video="assets/ar/ar_vid6.mp4"></section>
    <section>
      <h3>AR Ecosystem</h3>
    </section>
    <section>
      <p>AR Ecosystem<br>
        <span class="small"> (Understand what your app needs).</span></p>
      <p class="fragment  bullet small"><strong>*</strong>ARKit (Apple) - see last slide youtube</p>
      <p class="fragment  bullet small">ARCore (Google, Cross-platform)</p>
      <p class="fragment bullet small">AR Foundation (Unity)</p>
      <p class="fragment bullet small">Lumin (Magic Leap)</p>
      <p class="fragment  bullet small">Vuforia (cross-platform)</p>
      <p class="fragment bullet small">Wikitude (cross-platform & HUDS)</p>
      <p class="fragment bullet small">MaxSt(cross-platform/ html5)</p>
      <p class="fragment bullet small">Deep AR (real-time emotion detection)</p>
      <p class="fragment bullet small">Easy AR (6 DOF camera pose tracking)</p>
      <p class="fragment bullet small">8Th wall, A-frame, AR.js for Web AR </p>
    </section>
    <section data-background="assets/ar/artable.jpg" data-background-size="800px" data-background-color="#524d4f">
      <p class="fragment fade-out">AR SDK feature Comparison</p>
    </section>
    <section>
      <p>Immersion & Presence in AR</p>
    </section>
    <section>
      <p>Does the device matter? <br>
(HMD vs mobile for immersion)</p>
    </section>
    <section>
      <p>Stereoscopic AR (HMD) vs Single AR (Mobile) does not effect the sense of immersion.</p>
      <p>Stereoscopic AR in comparison to single AR can result in more emotional involvement and enjoyment.</p>
      <p class="tiny">Sense of Immersion in Computer Games Using Single and Stereoscopic Augmented Reality Sekhavat, Yoones A; Zarei, Hossein</p>
    </section>
    <section>
      <h3>AR Affordances</h3>
      <p class="fragment tight bullet" style="">Affordances are an object's properties that show the possible actions users can take with it, thereby suggesting how they may interact with that object. For instance, a button can look as if it needs to be turned or pushed.</p>
    </section>
    <section>
      <p>Participants perceive a significant difference between physical reality and both VR and AR for all proposed affordances, and that for many affordances, users perceive a difference in the ability of AR and VR to enact them.</p>
        <p class="tiny">(Framework of Affordances for Virtual Reality and Augmented Reality,  2019)</p>
    </section>
    <section>
      <p>VR strives to establish a sense of presence in a virtual environment, AR maintains a sense of presence in a user's immediate physical surroundings.</p>
    </section>
    <section>
      <p>In Augmented reality, the environment is already real. The focus is making real the interaction between the virtual characters and the real environment</p>
      <p>This has comparisons with fidelity, interaction fidelity and useabilty.</p>
    </section>
    <section>
      <p>Context immersion - refers to awareness experience using synthesized interaction and communication 
          <br>
(focuses on User experience)</p>
      <p class="tiny">A framework for context immersion in mobile augmented reality, Mi JeongKim,2012</p>
    </section>
    <section>
      <p>Fischer, Bartz, and Straber argued that <span class="fragment highlight-red">AR blurs the boundaries</span> between virtual and real objects that results in a better sense of immersion. </p>
    </section>
    <section>
      <p>We will discuss measuring AR in more detail next with along with looking at MR</p>
    </section>
     
          <section data-background-video="assets/heros.mp4"> </section>
    <section>
      <h3>Interesting Books</h3>
      <div class="half"> <img src="assets/ar/book1.jpg"/>
        <p class="tiny"><strong>Practical Augmented Reality</strong> by Steve Aukstakalnis.</p>
      </div>
      <div class="half"> <img src="assets/ar/book2.jpg"/>
        <p class="tiny"><strong>Augmented Human: How Technology Is Shaping the New Reality</strong> by Helen Papagiannis. </p>
      </div>
    </section>
      
          <section>
      <h2>Fridays Workshop</h2>
              <p class="">(Will be online)</p>
    </section>
      
          <section data-background-size="contain" data-background-video="assets/workshop1.mp4"></section>
      
      
    <section>
      <h3>Check out AR KIT 3 features in the nect slide (20 mins)</h3>
    </section>
    <section>
      <iframe width="100%" height="900" src="https://www.youtube.com/embed/6I9bgFtttvI" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
    </section>
    <section data-background-transition="convex" data-background-video="https://wayne-christian.github.io/WEB-AUTH-PRESENTATIONS/assets//week1assets/jumpfail.mp4">
      <h3>Fail to prepare<br>
        Prepare to fail!</h3>
    </section>
    <section>
      <h2>Boom!</h2>
    </section>
  </div>
</div>
<script src="lib/js/head.min.js"></script> 
<script src="js/reveal.js"></script> 
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script> 
<script src="https://code.highcharts.com/highcharts.js"></script> 
<script src="https://code.highcharts.com/highcharts-more.js"></script> 
<script src="https://code.highcharts.com/modules/solid-gauge.js"></script> 
<script src="js/themes/mypbtheme.js"></script> 
<script src="js/jquery.animateNumber.min.js"></script> 
<script src="js/main.js"></script> 
<script>
	var link = document.createElement( 'link' );
	link.rel = 'stylesheet';
	link.type = 'text/css';
	link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
	document.getElementsByTagName( 'head' )[0].appendChild( link );
</script>
</body>
</html>
